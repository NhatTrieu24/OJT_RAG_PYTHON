import os
import io
import time
import threading
import requests
import uvicorn
import vertexai
import psycopg2
import fitz  # PyMuPDF (Chuy√™n tr·ªã PDF)
import json
from contextlib import asynccontextmanager
from fastapi import FastAPI, UploadFile, File, Form, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from apscheduler.schedulers.background import BackgroundScheduler
gcp_json_content = os.environ.get("GCP_SERVICE_ACCOUNT_JSON")

if gcp_json_content:
    # N·∫øu bi·∫øn n√†y ch·ª©a n·ªôi dung JSON (b·∫Øt ƒë·∫ßu b·∫±ng {), ta ghi n√≥ ra file
    if gcp_json_content.strip().startswith("{"):
        print("üîë [Auth] Ph√°t hi·ªán JSON Content t·ª´ Env Var. ƒêang t·∫°o file t·∫°m...")
        cred_path = "google_creds.json"
        with open(cred_path, "w") as f:
            f.write(gcp_json_content)
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = os.path.abspath(cred_path)
    # N·∫øu n√≥ l√† ƒë∆∞·ªùng d·∫´n file
    else:
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = gcp_json_content
# Import logic t·ª´ agent_adk
from agent_adk import run_agent, run_cv_review, sync_all_data,SYNC_STATE

# ==================== C·∫§U H√åNH H·ªÜ TH·ªêNG ====================
PROJECT_ID = os.environ.get("PROJECT_ID", "reflecting-surf-477600-p4")
LOCATION = os.environ.get("LOCATION", "us-central1")
DB_DSN = os.environ.get("DB_DSN", "postgresql://postgres:123@caboose.proxy.rlwy.net:54173/railway")

# Key Google Cloud
render_secret = "/etc/secrets/GCP_SERVICE_ACCOUNT_JSON"
local_key = "rag-service-account.json" 

if os.path.exists(render_secret): 
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = render_secret
elif os.path.exists(local_key): 
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = os.path.abspath(local_key)

sync_status = {
    "is_running": False,
    "current_step": "S·∫µn s√†ng",
    "progress": "0/0",
    "percentage": "0%",
    "last_finished": None
}

# ==================== LIFESPAN ====================
def start_scheduler():
    scheduler = BackgroundScheduler()
    scheduler.add_job(sync_all_data, 'interval', hours=2, args=[False])
    scheduler.start()
    print("‚è∞ [Scheduler] ƒê√£ k√≠ch ho·∫°t t·ª± ƒë·ªông ƒë·ªìng b·ªô m·ªói 2 gi·ªù.")

def keep_alive():
    RENDER_URL = os.environ.get("RENDER_EXTERNAL_URL") 
    if not RENDER_URL: return
    time.sleep(30)
    while True:
        try:
            requests.get(RENDER_URL, timeout=10)
            print(f"‚öì [Keep-Alive] Ping {RENDER_URL}")
        except: pass
        time.sleep(600)

@asynccontextmanager
async def lifespan(app: FastAPI):
    try:
        vertexai.init(project=PROJECT_ID, location=LOCATION)
        print(f"‚úÖ [Startup] Vertex AI initialized ({LOCATION})")
    except Exception as e:
        print(f"‚ö†Ô∏è [Startup] Vertex AI Warning: {e}")

    start_scheduler()
    if os.environ.get("RENDER"):
        threading.Thread(target=keep_alive, daemon=True).start()

    yield
    print("üëã [Shutdown] Server stopping...")

# ==================== APP INITIALIZATION ====================
app = FastAPI(title="OJT RAG V8", version="4.0", lifespan=lifespan)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== API ENDPOINTS ====================

@app.get("/")
async def root():
    return {"status": "Live", "mode": "PDF Only", "db": "Connected"}

@app.post("/chat")
async def chat_endpoint(
    question: str = Form(...), 
    file: UploadFile = File(None)
):
    try:
        file_content = ""
        has_valid_file = False

        # --- B∆Ø·ªöC 1: KI·ªÇM TRA FILE (N·∫æU C√ì) ---
        if file and file.filename:
            # 1.1 CHECK ƒêU√îI FILE (B·∫ÆT BU·ªòC PDF)
            if not file.filename.lower().endswith(".pdf"):
                print(f"‚ö†Ô∏è [Upload] T·ª´ ch·ªëi file: {file.filename} (Kh√¥ng ph·∫£i PDF)")
                return {
                    "answer": "‚ùå H·ªá th·ªëng ch·ªâ h·ªó tr·ª£ ƒë·ªãnh d·∫°ng PDF. Vui l√≤ng t·∫£i l√™n file .pdf ƒë·ªÉ ƒë∆∞·ª£c ph√¢n t√≠ch.",
                    "active_model": "File Error",
                    "sql_debug": "Invalid Format"
                }

            # 1.2 ƒê·ªåC N·ªòI DUNG PDF
            content_bytes = await file.read()
            
            # Check file r·ªóng (0 bytes)
            if len(content_bytes) > 0:
                print(f"üìÇ [Upload] ƒêang ƒë·ªçc PDF: {file.filename} ({len(content_bytes)} bytes)")
                try:
                    # D√πng PyMuPDF (Fitz) ƒë·ªÉ ƒë·ªçc si√™u nhanh
                    with fitz.open(stream=content_bytes, filetype="pdf") as doc:
                        file_content = "\n".join([page.get_text() for page in doc])
                        has_valid_file = True
                except Exception as e:
                    print(f"‚ö†Ô∏è L·ªói ƒë·ªçc PDF: {e}")
                    return {
                        "answer": "‚ùå File PDF b·ªã l·ªói ho·∫∑c ƒë·∫∑t m·∫≠t kh·∫©u. Vui l√≤ng th·ª≠ file kh√°c.",
                        "active_model": "PDF Error",
                        "sql_debug": str(e)
                    }
            else:
                print("‚ö†Ô∏è [Upload] File PDF r·ªóng (0 bytes). B·ªè qua.")

        # --- B∆Ø·ªöC 2: CH·∫†Y LOGIC ---
        
        # MODE 1: REVIEW CV (C√≥ PDF + N·ªôi dung > 50 k√Ω t·ª±)
        if has_valid_file and len(file_content.strip()) > 50:
            print("ü§ñ [Mode] CV Review (PDF detected)")
            answer, mode = run_cv_review(file_content, question)
        
        # MODE 2: CHAT TH∆Ø·ªúNG (Kh√¥ng c√≥ file ho·∫∑c file l·ªói)
        else:
            print("ü§ñ [Mode] RAG Chat (No file)")
            answer, mode = run_agent(question, file_content=None)

        return {
            "answer": answer, 
            "active_model": mode, 
            "sql_debug": mode
        }

    except Exception as e:
        print(f"‚ùå Server Error: {e}")
        return JSONResponse(
            content={"answer": "L·ªói x·ª≠ l√Ω server.", "error": str(e)}, 
            status_code=500
        )

# ==================== SYNC WORKER ====================
def sync_worker(force_reset: bool):
    global sync_status
    sync_status["is_running"] = True
    sync_status["current_step"] = "ƒêang ƒë·ªìng b·ªô..."
    try:
        sync_all_data(force_reset)
        conn = psycopg2.connect(dsn=DB_DSN)
        cur = conn.cursor()
        cur.execute("""
            SELECT SUM(cnt), SUM(idx) FROM (
                SELECT COUNT(*) as cnt, COUNT(embedding) as idx FROM ojtdocument
                UNION ALL SELECT COUNT(*), COUNT(embedding) FROM job_position
                UNION ALL SELECT COUNT(*), COUNT(embedding) FROM company
            ) as s
        """)
        total, indexed = cur.fetchone()
        sync_status["progress"] = f"{indexed or 0}/{total or 0}"
        sync_status["percentage"] = f"{(indexed/(total or 1))*100:.1f}%"
        sync_status["current_step"] = "Ho√†n t·∫•t"
        conn.close()
    except Exception as e:
        sync_status["current_step"] = f"L·ªói: {e}"
    finally:
        sync_status["is_running"] = False
        sync_status["last_finished"] = time.strftime("%H:%M:%S %d/%m/%Y")

@app.get("/SyncNow")
async def sync_now(background_tasks: BackgroundTasks, force: bool = False):
    if sync_status["is_running"]: return {"message": "Busy"}
    background_tasks.add_task(sync_worker, force)
    return {"message": "Started"}

@app.get("/SyncStatus")
async def get_sync_status():
    """API tr·∫£ v·ªÅ ti·∫øn ƒë·ªô Real-time cho Frontend"""
    
    # 1. L·∫•y th√¥ng tin Text (ƒêang l√†m g√¨) t·ª´ agent_adk
    response = {
        "is_running": SYNC_STATE["is_running"],
        "step": SYNC_STATE["step"],       # VD: "ƒêang x·ª≠ l√Ω ojtdocument"
        "detail": SYNC_STATE["detail"],   # VD: "ƒêang ƒë·ªçc file: Report.pdf..."
        "progress_text": "0/0",
        "percentage": 0
    }

    # 2. L·∫•y con s·ªë th·ªëng k√™ th·ª±c t·∫ø t·ª´ DB (ƒê·ªÉ v·∫Ω thanh % ch√≠nh x√°c)
    try:
        conn = psycopg2.connect(dsn=DB_DSN)
        cur = conn.cursor()
        # ƒê·∫øm t·ªïng s·ªë d√≤ng ƒë√£ Index vs T·ªïng s·ªë d√≤ng
        cur.execute("""
            SELECT SUM(idx), SUM(cnt) FROM (
                SELECT COUNT(embedding) as idx, COUNT(*) as cnt FROM ojtdocument
                UNION ALL SELECT COUNT(embedding), COUNT(*) FROM job_position
                UNION ALL SELECT COUNT(embedding), COUNT(*) FROM company
                UNION ALL SELECT COUNT(embedding), COUNT(*) FROM "User"
            ) as s
        """)
        indexed, total = cur.fetchone()
        conn.close()

        total = total if total else 1
        indexed = indexed if indexed else 0
        
        response["progress_text"] = f"{indexed}/{total}"
        response["percentage"] = round((indexed / total) * 100, 1)

    except Exception:
        # N·∫øu l·ªói k·∫øt n·ªëi DB th√¨ tr·∫£ v·ªÅ s·ªë li·ªáu t·∫°m
        response["progress_text"] = "Checking..."
    
    return response

@app.get("/list_files")
async def list_files():
    try:
        conn = psycopg2.connect(dsn=DB_DSN)
        cur = conn.cursor()
        cur.execute('SELECT ojtdocument_id, title, file_url FROM ojtdocument ORDER BY ojtdocument_id DESC LIMIT 50')
        rows = cur.fetchall()
        conn.close()
        return {"files": [{"id": r[0], "display_name": r[1], "url": r[2]} for r in rows]}
    except Exception as e:
        return {"error": str(e)}

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)
