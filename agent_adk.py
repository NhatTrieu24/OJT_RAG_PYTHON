import os
import psycopg2
import vertexai
from vertexai.language_models import TextEmbeddingModel

# ==================== C·∫§U H√åNH & INIT ====================
key_path = "rag-service-account.json"
if os.path.exists(key_path):
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = os.path.abspath(key_path)

PROJECT_ID = os.getenv("PROJECT_ID", "reflecting-surf-477600-p4")
LOCATION = os.getenv("LOCATION", "europe-west4")
DB_DSN = os.getenv("DB_DSN", "postgresql://postgres:123@caboose.proxy.rlwy.net:54173/railway")

embedding_model = None
try:
    vertexai.init(project=PROJECT_ID, location=LOCATION)
    embedding_model = TextEmbeddingModel.from_pretrained("text-embedding-004")
    print("‚úÖ [Agent] Vertex AI Ready.")
except Exception as e:
    print(f"‚ö†Ô∏è [Agent] Init Error: {e}")

 #==================== SYNC MISSING EMBEDDINGS ====================
import time # Th√™m import n√†y ·ªü ƒë·∫ßu file

def sync_missing_embeddings():
    """ƒê·ªìng b·ªô Vector c√≥ c∆° ch·∫ø ngh·ªâ ƒë·ªÉ tr√°nh l·ªói Quota 429"""
    print("üîÑ [System] ƒêang ki·ªÉm tra d·ªØ li·ªáu m·ªõi ƒë·ªÉ ƒë·ªìng b·ªô Vector...")
    conn = None
    try:
        conn = psycopg2.connect(dsn=DB_DSN)
        cur = conn.cursor()
        
       # Th√™m v√†o targets trong agent_adk.py
        targets = [
    ("semester", "name", "semester_id"),
    ("major", "major_title", "major_id"),
    ("company", "name", "company_id"),
    ("ojtdocument", "title", "ojtdocument_id"),
    ("job_position", "job_title", "job_position_id"),
    ("job_description", "job_description", "job_description_id"),
    ("finalreport", "student_report_text", "finalreport_id"),
    ("companydocument", "title", "companydocument_id")
                ]
        
        updated_count = 0
        for table, text_col, id_col in targets:
            existing_cols = get_existing_columns(cur, table)
            
            if text_col in existing_cols and "embedding" in existing_cols:
                cur.execute(f"SELECT {id_col}, {text_col} FROM \"{table}\" WHERE embedding IS NULL")
                rows = cur.fetchall()
                
                for row_id, text in rows:
                    if not text: continue
                    
                    vector = get_query_embedding(text)
                    if vector:
                        cur.execute(f"UPDATE \"{table}\" SET embedding = %s WHERE {id_col} = %s", (vector, row_id))
                        updated_count += 1
                        
                        # NGH·ªà 1 GI√ÇY gi·ªØa c√°c request ƒë·ªÉ kh√¥ng b·ªã Google ch·∫∑n
                        time.sleep(1) 
                        
                        # Commit m·ªói 5 d√≤ng ƒë·ªÉ ƒë·∫£m b·∫£o d·ªØ li·ªáu ƒë∆∞·ª£c l∆∞u d·∫ßn
                        if updated_count % 5 == 0:
                            conn.commit()
                            print(f"   ‚àü ƒê√£ x·ª≠ l√Ω {updated_count} d√≤ng...")
            
        conn.commit()
        print(f"‚úÖ [System] Ho√†n t·∫•t! ƒê√£ c·∫≠p nh·∫≠t th√™m {updated_count} vector.")
            
    except Exception as e:
        print(f"‚ùå [System] L·ªói ƒë·ªìng b·ªô: {e}")
    finally:
        if conn: conn.close()
# ==================== CORE FUNCTIONS ====================

def get_query_embedding(text):
    if not embedding_model or not text: return None
    try:
        # C·∫Øt ng·∫Øn text ƒë·ªÉ tr√°nh qu√° gi·ªõi h·∫°n token c·ªßa model
        return embedding_model.get_embeddings([text[:2000]])[0].values
    except Exception as e:
        print(f"‚ùå Embedding Error: {e}")
        return None

def get_existing_columns(cur, table_name):
    """Ki·ªÉm tra c√°c c·ªôt th·ª±c t·∫ø ƒë·ªÉ tr√°nh l·ªói UndefinedColumn"""
    try:
        # S·ª≠ d·ª•ng ngo·∫∑c k√©p ƒë·ªÉ x·ª≠ l√Ω b·∫£ng c√≥ t√™n ƒë·∫∑c bi·ªát nh∆∞ "User"
        cur.execute(f"SELECT * FROM \"{table_name}\" LIMIT 0")
        return [desc[0] for desc in cur.description]
    except:
        return []

def search_vectors(question, target_table="auto", limit=5):
    """
    T√¨m ki·∫øm th√¥ng minh tr√™n nhi·ªÅu b·∫£ng s·ª≠ d·ª•ng PGVector.
    """
    print(f"üîç [Search] ƒêang t√¨m: '{question}'...")
    query_vector = get_query_embedding(question)
    if not query_vector: 
        return "H·ªá th·ªëng ƒëang g·∫∑p s·ª± c·ªë khi t·∫°o vector t√¨m ki·∫øm."

    conn = None
    try:
        conn = psycopg2.connect(dsn=DB_DSN)
        cur = conn.cursor()
        
        # 1. PH√ÇN LO·∫†I √ù ƒê·ªäNH ƒê·ªÇ CH·ªåN B·∫¢NG
        tables_to_search = []
        q_lower = question.lower()
        
        # Mapping t·ª´ kh√≥a -> B·∫£ng
        mapping = {
            "ojtdocument": ["ojt", "t√†i li·ªáu", "quy ƒë·ªãnh", "h∆∞·ªõng d·∫´n", "quy tr√¨nh", "bi·ªÉu m·∫´u", "h·ª£p ƒë·ªìng"],
            "job_position": ["job", "vi·ªác l√†m", "tuy·ªÉn d·ª•ng", "v·ªã tr√≠", "th·ª±c t·∫≠p", "l∆∞∆°ng", "salary", "dev", "engineer"],
            "company": ["c√¥ng ty", "ƒë·ªãa ch·ªâ", "website", "li√™n h·ªá", "email", "tax", "m√£ s·ªë thu·∫ø"],
            "semester": ["k·ª≥ h·ªçc", "h·ªçc k·ª≥", "semester", "spring", "summer", "fall", "b·∫Øt ƒë·∫ßu", "k·∫øt th√∫c"],
            "major": ["ng√†nh", "chuy√™n ng√†nh", "major", "h·ªçc v·ªÅ g√¨"]
        }

        for table, keywords in mapping.items():
            if any(k in q_lower for k in keywords):
                tables_to_search.append(table)
        
        # N·∫øu kh√¥ng b·∫Øt ƒë∆∞·ª£c t·ª´ kh√≥a ho·∫∑c AI y√™u c·∫ßu t√¨m b·∫£ng c·ª• th·ªÉ
        if target_table in mapping.keys():
            tables_to_search = [target_table]
        elif not tables_to_search:
            tables_to_search = ["ojtdocument", "job_position", "company"]

        final_results = []
        
        # 2. TRUY V·∫§N VECTOR TR√äN C√ÅC B·∫¢NG ƒê√É CH·ªåN
        for table in tables_to_search:
            existing_cols = get_existing_columns(cur, table)
            if not existing_cols or "embedding" not in existing_cols:
                continue

            # ∆Øu ti√™n c√°c c·ªôt ch·ª©a th√¥ng tin quan tr·ªçng ƒë·ªÉ tr·∫£ v·ªÅ cho AI
            priority_cols = [
                "title", "name", "job_title", "fullname", "major_title",
                "requirements", "address", "website", "salary_range", "start_date"
            ]
            valid_cols = [c for c in priority_cols if c in existing_cols]
            if not valid_cols:
                valid_cols = [c for c in existing_cols if c != 'embedding'][:3]

            cols_sql = ", ".join([f"\"{c}\"" for c in valid_cols])
            
            # C√¢u l·ªánh SQL Vector Search (Cosine distance)
            sql = f"""
                SELECT {cols_sql}, 1 - (embedding <=> %s::vector) as similarity
                FROM "{table}"
                WHERE embedding IS NOT NULL 
                ORDER BY embedding <=> %s::vector
                LIMIT %s;
            """
            cur.execute(sql, (query_vector, query_vector, limit))
            rows = cur.fetchall()
            
            for row in rows:
                score = row[-1]
                # Ng∆∞·ª°ng similarity 0.35 l√† m·ª©c trung b√¨nh an to√†n cho Ti·∫øng Vi·ªát
                if score and score > 0.35:
                    info = " | ".join([f"{valid_cols[i]}: {row[i]}" for i in range(len(valid_cols)) if row[i]])
                    final_results.append(f"[{table.upper()}] {info} (Score: {score:.2f})")

        if not final_results:
            return "H·ªÜ TH·ªêNG: Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu li√™n quan trong kho l∆∞u tr·ªØ."
            
        return "\n".join(final_results)

    except Exception as e:
        print(f"‚ùå DB Error: {e}")
        return f"L·ªói truy v·∫•n c∆° s·ªü d·ªØ li·ªáu: {str(e)}"
    finally:
        if conn: conn.close()

# ==================== LOGIC CHAT & REVIEW ====================

def run_agent(question: str, file_content: str = None):
    from rag_core import start_chat_session, get_chat_response
    
    # L·∫•y d·ªØ li·ªáu th·ª±c t·∫ø t·ª´ DB qua Vector Search
    db_context = search_vectors(question)
    
    # K·∫øt h·ª£p context t·ª´ file (n·∫øu c√≥) v√† d·ªØ li·ªáu t·ª´ DB
    full_prompt = f"D·ªÆ LI·ªÜU T·ª™ DATABASE:\n{db_context}\n\n"
    if file_content:
        full_prompt += f"D·ªÆ LI·ªÜU T·ª™ FILE UPLOAD:\n{file_content}\n\n"
    full_prompt += f"C√ÇU H·ªéI NG∆Ø·ªúI D√ôNG: {question}"

    chat_session = start_chat_session()
    response = get_chat_response(chat_session, full_prompt)
    return response, "Mode: Vector Search"

def run_cv_review(cv_text: str, user_message: str):
    from rag_core import start_chat_session
    
    # T√¨m job ph√π h·ª£p v·ªõi CV trong DB
    matched_jobs = search_vectors(cv_text, target_table="job_position", limit=3)
    
    prompt = f"""
    B·∫°n l√† m·ªôt chuy√™n gia HR. H√£y th·ª±c hi·ªán 2 nhi·ªám v·ª•:
    1. Nh·∫≠n x√©t CV: {cv_text[:3000]}
    2. D·ª±a v√†o danh s√°ch Job sau: {matched_jobs}, h√£y t∆∞ v·∫•n v·ªã tr√≠ ph√π h·ª£p nh·∫•t.
    3. Tr·∫£ l·ªùi y√™u c·∫ßu ri√™ng c·ªßa ·ª©ng vi√™n: {user_message}
    """
    
    chat_session = start_chat_session()
    response = chat_session.send_message(prompt)
    return response.text, "Mode: CV Review"