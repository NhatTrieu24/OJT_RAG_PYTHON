import os
import time
import psycopg2
import vertexai
from vertexai.language_models import TextEmbeddingModel
from tenacity import retry, stop_after_attempt, wait_exponential

# ==================== 1. C·∫§U H√åNH ====================
key_path = "rag-service-account.json"
if os.path.exists(key_path):
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = os.path.abspath(key_path)

PROJECT_ID = os.getenv("PROJECT_ID", "reflecting-surf-477600-p4")
LOCATION = os.getenv("LOCATION", "us-west1")
DB_DSN = os.getenv("DB_DSN","postgresql://postgres:123@caboose.proxy.rlwy.net:54173/railway")

embedding_model = None
try:
    vertexai.init(project=PROJECT_ID, location=LOCATION)
    embedding_model = TextEmbeddingModel.from_pretrained("text-embedding-004")
    print("‚úÖ [Agent] Vertex AI & Embedding Model Ready.")
except Exception as e:
    print(f"‚ö†Ô∏è [Agent] Init Error: {e}")

# ==================== 2. EMBEDDING (BATCH & RETRY) ====================

@retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=2, min=5, max=60))
def get_embeddings_batch(texts):
    if not embedding_model or not texts: return []
    # L√†m s·∫°ch vƒÉn b·∫£n ƒë·ªÉ tr√°nh l·ªói ƒë·ªãnh d·∫°ng
    clean_texts = [str(t).replace("\n", " ").strip()[:3000] for t in texts if t]
    if not clean_texts: return []
    try:
        embeddings = embedding_model.get_embeddings(clean_texts)
        return [e.values for e in embeddings]
    except Exception as e:
        print(f"‚ö†Ô∏è API Warning: {e}. ƒêang th·ª≠ l·∫°i...")
        raise e

def get_query_embedding(text):
    res = get_embeddings_batch([text])
    return res[0] if res else None

# ==================== 3. ƒê·ªíNG B·ªò VECTOR TO√ÄN DI·ªÜN ====================

def get_existing_columns(cur, table_name):
    try:
        cur.execute(f'SELECT * FROM "{table_name}" LIMIT 0')
        return [desc[0] for desc in cur.description]
    except: return []

def sync_missing_embeddings():
    print("üîÑ [System] ƒêang ƒë·ªìng b·ªô Vector cho to√†n b·ªô Schema...")
    conn = None
    try:
        conn = psycopg2.connect(dsn=DB_DSN)
        cur = conn.cursor()
        
        targets = [
            ("semester", "name", "semester_id"),
            ("major", "major_title", "major_id"),
            ("company", "name", "company_id"),
            ("ojtdocument", "title", "ojtdocument_id"),
            ("companydocument", "title", "companydocument_id"),
            ("job_position", "job_title", "job_position_id"),
            ("job_description", "job_description", "job_description_id"),
            ("job_title_overview", "job_title", "job_title_id"),
            ("finalreport", "student_report_text", "finalreport_id"),
            ("message", "content", "message_id"),
            ("User", "fullname", "user_id")
        ]
        
        total = 0
        for table, text_col, id_col in targets:
            cols = get_existing_columns(cur, table)
            if text_col not in cols or "embedding" not in cols: continue

            cur.execute(f'SELECT "{id_col}", "{text_col}" FROM "{table}" WHERE embedding IS NULL AND "{text_col}" IS NOT NULL')
            rows = cur.fetchall()
            if not rows: continue
            
            print(f"   ‚àü B·∫£ng [{table}]: X·ª≠ l√Ω {len(rows)} d√≤ng.")
            batch_size = 50
            for i in range(0, len(rows), batch_size):
                batch = rows[i:i+batch_size]
                v = get_embeddings_batch([r[1] for r in batch])
                for j, vec in enumerate(v):
                    cur.execute(f'UPDATE "{table}" SET embedding = %s WHERE "{id_col}" = %s', (vec, batch[j][0]))
                conn.commit()
                total += len(batch)
                time.sleep(12) # L√°ch Quota 429
        print(f"üéâ [System] Ho√†n t·∫•t ƒë·ªìng b·ªô {total} d√≤ng.")
    except Exception as e: print(f"‚ùå L·ªói ƒë·ªìng b·ªô: {e}")
    finally:
        if conn: conn.close()

# ==================== 4. SEARCH & RAG LOGIC (FIXED) ====================

def search_vectors(question, target_table="auto", limit=5):
    query_vector = get_query_embedding(question)
    if not query_vector: return ""

    conn = None
    try:
        conn = psycopg2.connect(dsn=DB_DSN)
        cur = conn.cursor()
        
        # 1. M·ªü r·ªông b·ªô l·ªçc Mapping ƒë·ªÉ bao qu√°t c√°c b·∫£ng quan tr·ªçng
        mapping = {
            "semester": ["k·ª≥", "h·ªçc k·ª≥", "semester", "spring", "summer", "fall", "2025", "2024", "b·∫Øt ƒë·∫ßu", "k·∫øt th√∫c"],
            "company": ["c√¥ng ty", "ƒë·ªãa ch·ªâ", "website", "fpt", "momo", "viettel", "li√™n h·ªá"],
            "ojtdocument": ["ojt", "quy ƒë·ªãnh", "h∆∞·ªõng d·∫´n", "t√†i li·ªáu", "quy tr√¨nh", "bi·ªÉu m·∫´u"],
            "job_position": ["vi·ªác l√†m", "tuy·ªÉn d·ª•ng", "job", "l∆∞∆°ng", "salary", "th·ª±c t·∫≠p", "v·ªã tr√≠"]
        }

        tables_to_search = []
        q_lower = question.lower()
        for tbl, keywords in mapping.items():
            if any(k in q_lower for k in keywords):
                tables_to_search.append(tbl)
        
        # FIX: N·∫øu h·ªèi v·ªÅ th·ªùi gian/k·ª≥ h·ªçc nh∆∞ng Mapping ch∆∞a b·∫Øt ƒë∆∞·ª£c b·∫£ng semester
        if any(k in q_lower for k in ["khi n√†o", "th·ªùi gian", "k·ª≥ h·ªçc", "b·∫Øt ƒë·∫ßu"]):
            if "semester" not in tables_to_search:
                tables_to_search.append("semester")

        # 2. N·∫øu v·∫´n kh√¥ng th·∫•y b·∫£ng n√†o, bu·ªôc ph·∫£i t√¨m ·ªü 3 b·∫£ng c·ªët l√µi
        if not tables_to_search:
            tables_to_search = ["ojtdocument", "job_position", "semester", "company"]

        final_results = []
        # Lo·∫°i b·ªè b·∫£ng tr√πng l·∫∑p
        tables_to_search = list(set(tables_to_search))

        for table in tables_to_search:
            cols = get_existing_columns(cur, table)
            if "embedding" not in cols: continue

            # Schema hi·ªÉn th·ªã chu·∫©n cho t·ª´ng b·∫£ng
            d_map = {
                "semester": ["name", "start_date", "end_date", "is_active"],
                "company": ["name", "address", "website"],
                "ojtdocument": ["title", "file_url"],
                "job_position": ["job_title", "location", "salary_range"]
            }
            s_cols = [c for c in d_map.get(table, []) if c in cols] or cols[:2]
            cols_sql = ", ".join([f'"{c}"' for c in s_cols])

            # Th·ª±c hi·ªán Vector Search (Cosine Similarity)
            sql = f'SELECT {cols_sql}, 1 - (embedding <=> %s::vector) as sim FROM "{table}" WHERE embedding IS NOT NULL ORDER BY embedding <=> %s::vector LIMIT 3'
            cur.execute(sql, (query_vector, query_vector))
            
            for r in cur.fetchall():
                score = r[-1]
                # N·ªõi l·ªèng ng∆∞·ª°ng cho c√°c t·ª´ kh√≥a ng·∫Øn ho·∫∑c t√™n ri√™ng (Spring, MoMo, FPT)
                threshold = 0.30 if (len(q_lower) < 15 or any(k in q_lower for k in ["spring", "momo", "fpt"])) else 0.38
                
                if score and score > threshold:
                    # L·ªçc b·ªè nhi·ªÖu l·ªói k·ªπ thu·∫≠t
                    if any(err in str(r[0]).lower() for err in ["l·ªói", "error", "undefined"]): continue
                    
                    content = " | ".join([f"{s_cols[j]}: {r[j]}" for j in range(len(s_cols)) if r[j]])
                    final_results.append(f"[{table.upper()}] {content}")

        return "\n".join(final_results)
    except Exception as e:
        print(f"‚ùå Search Error: {e}")
        return ""
    finally:
        if conn: conn.close()

def run_agent(question: str, file_content: str = None):
    from rag_core import start_chat_session, get_chat_response
    
    # 1. Tr√≠ch xu·∫•t context
    db_context = search_vectors(question)
    
    # 2. X√¢y d·ª±ng Prompt ch·∫∑t ch·∫Ω
    prompt = f"""
    D·ªÆ LI·ªÜU H·ªÜ TH·ªêNG (B·∫ÆT BU·ªòC S·ª¨ D·ª§NG):
    {db_context if db_context else "Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu li√™n quan trong DB."}
    
    FILE NG∆Ø·ªúI D√ôNG: {file_content if file_content else "N/A"}
    
    C√ÇU H·ªéI: {question}
    
    Y√äU C·∫¶U:
    - N·∫øu c√≥ d·ªØ li·ªáu trong 'D·ªÆ LI·ªÜU H·ªÜ TH·ªêNG', h√£y d√πng n√≥ ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c th√¥ng tin (ƒë·ªãa ch·ªâ, website, l∆∞∆°ng...).
    - N·∫øu d·ªØ li·ªáu tr·ªëng, h√£y l·ªãch s·ª± th√¥ng b√°o ch∆∞a c√≥ d·ªØ li·ªáu ch√≠nh th·ª©c.
    - Kh√¥ng b·ªãa ƒë·∫∑t th√¥ng tin n·∫±m ngo√†i d·ªØ li·ªáu tr√™n.
    """
    
    print(f"--- DEBUG CONTEXT SENT TO AI ---\n{db_context}\n-------------------------------")
    
    chat_session = start_chat_session()
    return get_chat_response(chat_session, prompt), "Mode: Clean RAG Vector"

def run_cv_review(cv_text: str, user_message: str):
    from rag_core import start_chat_session
    # T√¨m job ph√π h·ª£p v·ªõi CV
    matched_jobs = search_vectors(cv_text, target_table="job_position", limit=3)
    prompt = f"CV: {cv_text[:3000]}\nJob g·ª£i √Ω t·ª´ h·ªá th·ªëng: {matched_jobs}\nY√™u c·∫ßu: {user_message}"
    chat_session = start_chat_session()
    return chat_session.send_message(prompt).text, "Mode: CV Reviewer"

def check_vector_coverage():
    """
    Ki·ªÉm tra v√† b√°o c√°o t·ª∑ l·ªá ph·∫ßn trƒÉm d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c Vector h√≥a trong Database.
    """
    print("\nüìä [REPORT] KI·ªÇM TRA ƒê·ªò PH·ª¶ VECTOR TRONG DATABASE")
    print("-" * 60)
    conn = None
    try:
        conn = psycopg2.connect(dsn=DB_DSN)
        cur = conn.cursor()
        
        # Danh s√°ch c√°c b·∫£ng c·∫ßn ki·ªÉm tra
        targets = [
            ("semester", "semester_id"),
            ("major", "major_id"),
            ("company", "company_id"),
            ("ojtdocument", "ojtdocument_id"),
            ("job_position", "job_position_id"),
            ("job_description", "job_description_id"),
            ("finalreport", "finalreport_id"),
            ("companydocument", "companydocument_id"),
            ("User", "user_id")
        ]
        
        for table, id_col in targets:
            # Ki·ªÉm tra b·∫£ng c√≥ t·ªìn t·∫°i c·ªôt embedding kh√¥ng
            cur.execute(f"SELECT column_name FROM information_schema.columns WHERE table_name = '{table}'")
            cols = [r[0] for r in cur.fetchall()]
            
            if "embedding" not in cols:
                print(f"‚ö†Ô∏è  B·∫£ng [{table:.<18}]: Ch∆∞a c√≥ c·ªôt 'embedding'.")
                continue

            # ƒê·∫øm t·ªïng s·ªë d√≤ng v√† s·ªë d√≤ng thi·∫øu embedding
            cur.execute(f'SELECT COUNT(*), COUNT(embedding) FROM "{table}"')
            total, has_vector = cur.fetchone()
            missing = total - has_vector
            
            percentage = (has_vector / total * 100) if total > 0 else 0
            
            status = "‚úÖ OK" if missing == 0 and total > 0 else "‚ùå MISSING"
            if total == 0: status = "‚ö™ EMPTY"

            print(f"{status} [{table:.<18}]: {has_vector}/{total} d√≤ng ({percentage:>6.1f}%) | Thi·∫øu: {missing}")

        print("-" * 60)
        print("üí° G·ª£i √Ω: N·∫øu th·∫•y d√≤ng n√†o b√°o MISSING, h√£y ch·∫°y sync_missing_embeddings().\n")
            
    except Exception as e:
        print(f"‚ùå L·ªói khi ki·ªÉm tra: {e}")
    finally:
        if conn: conn.close()