import os
import re
import io
import time
import requests
import psycopg2
from psycopg2 import pool
import pdfplumber
import docx
from contextlib import contextmanager
from dotenv import load_dotenv
from tenacity import retry, stop_after_attempt, wait_fixed

# --- TH∆Ø VI·ªÜN AI LOCAL (QUAN TR·ªåNG) ---
from sentence_transformers import SentenceTransformer

load_dotenv()

# ==================== 1. C·∫§U H√åNH H·ªÜ TH·ªêNG ====================

# 1.1 C·∫•u h√¨nh Database & Connection Pool
LOCAL_DB_URL = "postgresql://postgres:123@caboose.proxy.rlwy.net:54173/railway"
DB_DSN = os.environ.get("DB_DSN", LOCAL_DB_URL)

db_pool = None
try:
    # T·∫°o b·ªÉ k·∫øt n·ªëi (Min 1, Max 10) ƒë·ªÉ tr√°nh m·ªü l·∫°i connection li√™n t·ª•c
    db_pool = psycopg2.pool.ThreadedConnectionPool(1, 10, dsn=DB_DSN)
    print("‚úÖ [DB] Connection Pool initialized.")
except Exception as e:
    print(f"‚ùå [DB] Pool Error: {e}")

# 1.2 C·∫•u h√¨nh AI Local (Embedding)
# D√πng model MiniLM: Nhanh, Nh·∫π (300MB RAM), Vector size 384
print("‚è≥ [AI Local] ƒêang t·∫£i Model Embedding (MiniLM)...")
try:
    local_embedder = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
    print("‚úÖ [AI Local] Model ƒë√£ s·∫µn s√†ng!")
except Exception as e:
    print(f"‚ùå [AI Local] Load Model Error: {e}")
    local_embedder = None

# ==================== 2. T·ª™ ƒêI·ªÇN & H√ÄM B·ªî TR·ª¢ ====================

# T·ª´ ƒëi·ªÉn vi·∫øt t·∫Øt (Regex) - Nhanh h∆°n g·ªçi AI g·∫•p 1000 l·∫ßn
ABBREVIATIONS = {
    r"\btt\b": "th·ª±c t·∫≠p",
    r"\bojt\b": "th·ª±c t·∫≠p doanh nghi·ªáp",
    r"\bmssv\b": "m√£ s·ªë sinh vi√™n",
    r"\bcv\b": "h·ªì s∆° xin vi·ªác",
    r"\bcty\b": "c√¥ng ty",
    r"\bdn\b": "doanh nghi·ªáp",
    r"\bsem\b": "h·ªçc k·ª≥",
    r"\bjob\b": "vi·ªác l√†m",
    r"\bluong\b": "m·ª©c l∆∞∆°ng",
    r"\bhcm\b": "TP.HCM",
    r"\bhn\b": "H√† N·ªôi"
}

def quick_process_text(text):
    """Chu·∫©n h√≥a text si√™u t·ªëc b·∫±ng Regex"""
    if not text: return ""
    text = text.lower().strip()
    for pattern, replacement in ABBREVIATIONS.items():
        text = re.sub(pattern, replacement, text)
    return re.sub(r'\s+', ' ', text)

@contextmanager
def get_db_connection():
    """L·∫•y k·∫øt n·ªëi t·ª´ Pool an to√†n"""
    conn = None
    try:
        if db_pool:
            conn = db_pool.getconn()
            yield conn
        else:
            conn = psycopg2.connect(dsn=DB_DSN)
            yield conn
    except Exception as e:
        print(f"‚ùå DB Error: {e}")
        raise e
    finally:
        if conn and db_pool: db_pool.putconn(conn)
        elif conn: conn.close()

def get_text_from_drive(file_url):
    """T·∫£i v√† ƒë·ªçc n·ªôi dung file PDF/Word t·ª´ Google Drive"""
    if not file_url or "drive.google.com" not in file_url: return ""
    try:
        match = re.search(r'/d/([a-zA-Z0-9_-]+)', file_url) or re.search(r'id=([a-zA-Z0-9_-]+)', file_url)
        if not match: return ""
        url = f"https://drive.google.com/uc?export=download&id={match.group(1)}"
        
        # Timeout 10s ƒë·ªÉ kh√¥ng treo server
        res = requests.get(url, timeout=10)
        if res.status_code == 200:
            stream = io.BytesIO(res.content)
            try:
                # ∆Øu ti√™n ƒë·ªçc PDF
                with pdfplumber.open(stream) as pdf:
                    return " ".join([p.extract_text() or "" for p in pdf.pages[:5]])
            except: 
                # Fallback sang Word
                stream.seek(0)
                doc = docx.Document(stream)
                return " ".join([p.text for p in doc.paragraphs])
    except: pass
    return ""

# ==================== 3. H√ÄM VECTOR LOCAL (KH√îNG T·ªêN QUOTA) ====================

def get_embeddings_batch(texts):
    """T·∫°o Vector b·∫±ng CPU Server (Free & Fast)"""
    if not local_embedder or not texts: return []
    # C·∫Øt ng·∫Øn text ƒë·ªÉ tr√°nh l·ªói model limit
    clean_texts = [str(t).replace("\n", " ").strip()[:1000] for t in texts if t]
    try:
        # encode tr·∫£ v·ªÅ numpy array -> c·∫ßn chuy·ªÉn th√†nh list
        embeddings = local_embedder.encode(clean_texts)
        return embeddings.tolist()
    except Exception as e:
        print(f"‚ö†Ô∏è Local Embed Error: {e}")
        return []

def get_query_embedding(text):
    """T·∫°o vector cho 1 c√¢u h·ªèi"""
    try:
        embedding = local_embedder.encode(text)
        return embedding.tolist()
    except: return None

# ==================== 4. SEARCH ENGINE (T·ªêI ∆ØU H√ìA) ====================

def search_vectors(question):
    t0 = time.time()
    
    # 1. T·∫°o vector c√¢u h·ªèi (Local)
    query_vector = get_query_embedding(question)
    if not query_vector: return ""
    
    results = []
    try:
        with get_db_connection() as conn:
            with conn.cursor() as cur:
                # 2. Query t·ªëi ∆∞u (G·ªôp 9 b·∫£ng)
                # L∆∞u √Ω: DB Vector c·ªôt ph·∫£i l√† vector(384)
                sql_query = """
                    (SELECT 'T√ÄI LI·ªÜU', last_content_indexed, (embedding <=> %s::vector) as d FROM ojtdocument WHERE embedding IS NOT NULL ORDER BY d ASC LIMIT 3)
                    UNION ALL
                    (SELECT 'VI·ªÜC L√ÄM', last_content_indexed, (embedding <=> %s::vector) as d FROM job_position WHERE embedding IS NOT NULL ORDER BY d ASC LIMIT 4)
                    UNION ALL
                    (SELECT 'DOANH NGHI·ªÜP', last_content_indexed, (embedding <=> %s::vector) as d FROM company WHERE embedding IS NOT NULL ORDER BY d ASC LIMIT 2)
                    UNION ALL
                    (SELECT 'H·ªí S∆† SV', last_content_indexed, (embedding <=> %s::vector) as d FROM "User" WHERE embedding IS NOT NULL ORDER BY d ASC LIMIT 2)
                    UNION ALL
                    (SELECT 'NG√ÄNH H·ªåC', last_content_indexed, (embedding <=> %s::vector) as d FROM major WHERE embedding IS NOT NULL ORDER BY d ASC LIMIT 2)
                    UNION ALL
                    (SELECT 'H·ªåC K·ª≤', last_content_indexed, (embedding <=> %s::vector) as d FROM semester WHERE embedding IS NOT NULL ORDER BY d ASC LIMIT 1)
                    UNION ALL
                    (SELECT 'DOC C√îNG TY', last_content_indexed, (embedding <=> %s::vector) as d FROM companydocument WHERE embedding IS NOT NULL ORDER BY d ASC LIMIT 2)
                    UNION ALL
                    (SELECT 'FEEDBACK', last_content_indexed, (embedding <=> %s::vector) as d FROM finalreport WHERE embedding IS NOT NULL ORDER BY d ASC LIMIT 2)
                    UNION ALL
                    (SELECT 'TH·ªêNG K√ä', last_content_indexed, (embedding <=> %s::vector) as d FROM job_title_overview WHERE embedding IS NOT NULL ORDER BY d ASC LIMIT 2)
                    ORDER BY d ASC LIMIT 12
                """
                # Truy·ªÅn tham s·ªë 9 l·∫ßn cho 9 d·∫•u %s
                params = (query_vector,) * 9 
                cur.execute(sql_query, params)
                
                for r in cur.fetchall():
                    # L·∫•y k·∫øt qu·∫£ c√≥ kho·∫£ng c√°ch < 0.65 (C√†ng nh·ªè c√†ng gi·ªëng)
                    if r[2] < 0.85: 
                        results.append(f"[{r[0]}] {r[1]}")
                        
    except Exception as e:
        print(f"‚ùå Search Error: {e}")
    
    print(f"‚ö° Local Search: {time.time() - t0:.3f}s")
    return "\n\n".join(results)

# ==================== 5. CORE RAG LOGIC ====================

def run_agent(question: str, file_content: str = None):
    # Import c·ª•c b·ªô ƒë·ªÉ tr√°nh l·ªói circular import
    from rag_core import start_chat_session, get_chat_response
    
    t_start = time.time()
    
    # 1. X·ª≠ l√Ω c√¢u h·ªèi
    clean_question = quick_process_text(question)
    print(f"üßπ Input: '{question}' -> '{clean_question}'")
    
    # 2. T√¨m ki·∫øm Vector (L·∫•y link file v√† t√≥m t·∫Øt)
    # L·∫•y nhi·ªÅu k·∫øt qu·∫£ h∆°n ch√∫t ƒë·ªÉ kh√¥ng b·ªè s√≥t
    db_context = search_vectors(clean_question) 
    
    # 3. K√çCH HO·∫†T ƒê·ªåC FILE DRIVE TR·ª∞C TI·∫æP (QUAN TR·ªåNG)
    # N·∫øu trong k·∫øt qu·∫£ t√¨m ki·∫øm c√≥ Link Drive, ta s·∫Ω ƒë·ªçc n·ªôi dung chi ti·∫øt c·ªßa n√≥
    realtime_file_content = ""
    source_link = ""
    
    if "drive.google.com" in db_context:
        # T√¨m link ƒë·∫ßu ti√™n xu·∫•t hi·ªán trong context (th∆∞·ªùng l√† link li√™n quan nh·∫•t)
        link_match = re.search(r'https://drive\.google\.com/[^\s]+', db_context)
        if link_match:
            target_url = link_match.group(0).rstrip(").,") # X√≥a d·∫•u c√¢u th·ª´a n·∫øu c√≥
            print(f"üöÄ [Real-time] Ph√°t hi·ªán t√†i li·ªáu li√™n quan. ƒêang ƒë·ªçc chi ti·∫øt: {target_url}")
            
            # G·ªçi h√†m t·∫£i v√† ƒë·ªçc file (M·∫•t kho·∫£ng 1-2s nh∆∞ng chi ti·∫øt c·ª±c k·ª≥)
            realtime_file_content = get_text_from_drive(target_url)
            
            if realtime_file_content:
                source_link = target_url
                print(f"   ‚úÖ ƒê√£ tr√≠ch xu·∫•t ƒë∆∞·ª£c {len(realtime_file_content)} k√Ω t·ª± chi ti·∫øt.")
            else:
                print("   ‚ö†Ô∏è Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c n·ªôi dung file (File ·∫£nh ho·∫∑c l·ªói quy·ªÅn truy c·∫≠p).")

    # 4. T·∫°o Prompt (B∆°m d·ªØ li·ªáu chi ti·∫øt v√†o)
    final_prompt = f"""
    VAI TR√í: Tr·ª£ l√Ω tuy·ªÉn d·ª•ng v√† ƒë√†o t·∫°o OJT chuy√™n nghi·ªáp.

    D·ªÆ LI·ªÜU T√ìM T·∫ÆT T·ª™ H·ªÜ TH·ªêNG:
    {db_context}
    
    --------------------------------------------------
    N·ªòI DUNG CHI TI·∫æT ƒê·∫¶Y ƒê·ª¶ T·ª™ T√ÄI LI·ªÜU (∆ØU TI√äN D√ôNG C√ÅI N√ÄY):
    {realtime_file_content if realtime_file_content else "Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c n·ªôi dung chi ti·∫øt file."}
    --------------------------------------------------
    
    FILE NG∆Ø·ªúI D√ôNG T·∫¢I L√äN (N·∫æU C√ì):
    {file_content if file_content else "N/A"}
    
    C√ÇU H·ªéI: {clean_question}
    
    Y√äU C·∫¶U TR·∫¢ L·ªúI: 
    1. D·ª±a v√†o 'N·ªòI DUNG CHI TI·∫æT', h√£y tr√≠ch xu·∫•t to√†n b·ªô th√¥ng tin quan tr·ªçng:
       - Gi·ªõi thi·ªáu c√¥ng ty.
       - V·ªã tr√≠ tuy·ªÉn d·ª•ng & Y√™u c·∫ßu k·ªπ nƒÉng (Hard/Soft skills).
       - Quy·ªÅn l·ª£i (L∆∞∆°ng, tr·ª£ c·∫•p, m√¥i tr∆∞·ªùng).
       - C√°ch th·ª©c ·ª©ng tuy·ªÉn (Email, Quy tr√¨nh).
    2. Tr√¨nh b√†y r√µ r√†ng, g·∫°ch ƒë·∫ßu d√≤ng.
    3. N·∫øu c√≥ link t√†i li·ªáu g·ªëc ({source_link}), H√ÉY ƒê·ªÇ N√ì ·ªû CU·ªêI C√ôNG ƒë·ªÉ ng∆∞·ªùi d√πng tham kh·∫£o.
    """
    
    # 5. G·ª≠i cho AI
    try:
        chat_session = start_chat_session()
        answer = get_chat_response(chat_session, final_prompt)
    except Exception as e:
        answer = "‚ö†Ô∏è H·ªá th·ªëng ƒëang b·∫≠n x·ª≠ l√Ω d·ªØ li·ªáu l·ªõn. Vui l√≤ng th·ª≠ l·∫°i c√¢u h·ªèi c·ª• th·ªÉ h∆°n."
        print(f"‚ùå Chat Error: {e}")
    
    print(f"‚è±Ô∏è Total Time: {time.time() - t_start:.3f}s")
    
    # ƒê√°nh d·∫•u mode ƒë·ªÉ d·ªÖ debug
    mode_label = "RAG Mode" if realtime_file_content else "RAG Fast Mode"
    
    return answer, mode_label

# ==================== 6. ƒê·ªíNG B·ªò D·ªÆ LI·ªÜU (SYNC ALL) ====================

def sync_all_data(force_reset=False):
    print(f"üîÑ [Sync] B·∫Øt ƒë·∫ßu ƒë·ªìng b·ªô d·ªØ li·ªáu (Local Embedding)...")
    t_start = time.time()
    
    try:
        with get_db_connection() as conn:
            with conn.cursor() as cur:
                if force_reset:
                    print("‚ö†Ô∏è [Reset] ƒêang x√≥a vector c≈©...")
                    tables = ["job_position", "company", "semester", "User", "major", "ojtdocument", "companydocument", "finalreport", "job_title_overview"]
                    for t in tables:
                        # Ki·ªÉm tra b·∫£ng t·ªìn t·∫°i
                        cur.execute(f"SELECT to_regclass('public.\"{t}\"');")
                        if cur.fetchone()[0]:
                            cur.execute(f'UPDATE "{t}" SET embedding = NULL, last_content_indexed = NULL;')
                    conn.commit()

                # --- ƒê·ªäNH NGHƒ®A K·ªäCH B·∫¢N (GI·ªêNG C≈® NH∆ØNG CH·∫†Y LOCAL) ---
                scenarios = [
                    # 1. Job
                    {"table": "job_position", "id": "job_position_id", "sql": """
                        SELECT jp.job_position_id, 'V·ªä TR√ç: ' || COALESCE(jp.job_title, '') || '. C√îNG TY: ' || COALESCE(c.name, 'N/A') || '. L∆Ø∆†NG: ' || COALESCE(jp.salary_range, '') || '. M√î T·∫¢: ' || COALESCE(jd.job_description, '') || '. Y√äU C·∫¶U: ' || COALESCE(jp.requirements, '') as text 
                        FROM job_position jp 
                        LEFT JOIN semester_company sc ON jp.semester_company_id = sc.semester_company_id
                        LEFT JOIN company c ON sc.company_id = c.company_id
                        LEFT JOIN job_description jd ON jp.job_position_id = jd.job_position_id
                    """},
                    # 2. User
                    {"table": "User", "id": "user_id", "sql": """
                        SELECT u.user_id, 'NG∆Ø·ªúI D√ôNG: ' || COALESCE(u.fullname, '') || '. MSSV: ' || COALESCE(u.student_code, '') || '. EMAIL: ' || COALESCE(u.email, '') || '. NG√ÄNH: ' || COALESCE(m.major_title, '') || '. C√îNG TY: ' || COALESCE(c.name, '') as text
                        FROM "User" u
                        LEFT JOIN major m ON u.major_id = m.major_id
                        LEFT JOIN company c ON u.company_id = c.company_id
                    """},
                    # 3. Docs (C√≥ ƒë·ªçc file)
                    {"table": "ojtdocument", "id": "ojtdocument_id", "sql": "SELECT ojtdocument_id, title, file_url FROM ojtdocument"},
                    {"table": "companydocument", "id": "companydocument_id", "sql": """
                        SELECT cd.companydocument_id, 'DOC C√îNG TY: ' || COALESCE(c.name, '') || '. T√äN: ' || COALESCE(cd.title, '') as text, cd.file_url 
                        FROM companydocument cd LEFT JOIN semester_company sc ON cd.semester_company_id = sc.semester_company_id LEFT JOIN company c ON sc.company_id = c.company_id
                    """},
                    # 4. C√°c b·∫£ng ƒë∆°n l·∫ª kh√°c
                    {"table": "company", "id": "company_id", "sql": "SELECT company_id, 'C√îNG TY: ' || COALESCE(name, '') || '. ƒê·ªäA CH·ªà: ' || COALESCE(address, '') || '. EMAIL: ' || COALESCE(contact_email, '') as text FROM company"},
                    {"table": "semester", "id": "semester_id", "sql": "SELECT semester_id, 'H·ªåC K·ª≤: ' || COALESCE(name, '') || '. T·ª™: ' || COALESCE(start_date::text, '') || ' ƒê·∫æN: ' || COALESCE(end_date::text, '') as text FROM semester"},
                    {"table": "major", "id": "major_id", "sql": "SELECT major_id, 'NG√ÄNH: ' || COALESCE(major_title, '') || '. M√î T·∫¢: ' || COALESCE(description, '') as text FROM major"},
                    {"table": "finalreport", "id": "finalreport_id", "sql": """
                         SELECT fr.finalreport_id, 'ƒê√ÅNH GI√Å: SV ' || COALESCE(u.fullname, '') || ' T·∫†I ' || COALESCE(c.name, '') || '. ƒêI·ªÇM: ' || COALESCE(fr.company_rating::text, '0') || '. NH·∫¨N X√âT: ' || COALESCE(fr.company_feedback, '') as text
                         FROM finalreport fr LEFT JOIN "User" u ON fr.user_id = u.user_id LEFT JOIN job_position jp ON fr.job_position_id = jp.job_position_id LEFT JOIN semester_company sc ON jp.semester_company_id = sc.semester_company_id LEFT JOIN company c ON sc.company_id = c.company_id
                    """},
                    {"table": "job_title_overview", "id": "job_title_id", "sql": "SELECT job_title_id, 'TH·ªêNG K√ä VI·ªÜC L√ÄM: ' || COALESCE(job_title, '') || '. S·ªê L∆Ø·ª¢NG: ' || COALESCE(position_amount::text, '0') as text FROM job_title_overview"}
                ]

                # --- LOOP X·ª¨ L√ù ---
                for sc in scenarios:
                    table = sc['table']
                    id_col = sc['id']
                    
                    cur.execute(f"SELECT to_regclass('public.\"{table}\"');")
                    if not cur.fetchone()[0]: continue

                    # L·∫•y d·ªØ li·ªáu ch∆∞a index
                    cur.execute(f"""
                        WITH source AS ({sc['sql']})
                        SELECT s.* FROM source s JOIN "{table}" t ON s.{id_col} = t."{id_col}"
                        WHERE t.embedding IS NULL OR t.last_content_indexed IS NULL
                    """)
                    rows = cur.fetchall()
                    if not rows: continue
                    
                    print(f"üì¶ [{table}] X·ª≠ l√Ω {len(rows)} d√≤ng m·ªõi.")
                    BATCH_SIZE = 10
                    
                    for i in range(0, len(rows), BATCH_SIZE):
                        batch = rows[i : i + BATCH_SIZE]
                        batch_texts, batch_ids = [], []

                        for r in batch:
                            rid = r[0]
                            # X·ª≠ l√Ω File Drive
                            if table in ["ojtdocument", "companydocument"]:
                                title = r[1]
                                url = r[2] if len(r) > 2 else ""
                                content = ""
                                if "drive.google.com" in url:
                                    print(f"   üì• ƒê·ªçc file: {title[:20]}...")
                                    content = get_text_from_drive(url)
                                final_text = f"{title}. CHI TI·∫æT: {content}. Link: {url}"
                            else:
                                final_text = r[1]
                            
                            batch_texts.append(final_text)
                            batch_ids.append(rid)

                        # T·∫°o Embedding LOCAL
                        vectors = get_embeddings_batch(batch_texts)
                        
                        # L∆∞u v√†o DB
                        if vectors:
                            for idx, vec in enumerate(vectors):
                                cur.execute(f'UPDATE "{table}" SET embedding = %s, last_content_indexed = %s WHERE "{id_col}" = %s', 
                                            (vec, batch_texts[idx], batch_ids[idx]))
                            conn.commit()
                            print(f"   ‚úÖ Saved batch {i//BATCH_SIZE + 1} (Local Vector).")

        print(f"üéâ [Sync] Ho√†n t·∫•t sau {time.time() - t_start:.2f}s.")
    except Exception as e:
        print(f"‚ùå L·ªói Sync: {e}")

# ==================== 7. CV REVIEW (N√ÇNG C·∫§P) ====================

def run_cv_review(cv_text: str, user_message: str):
    from rag_core import start_chat_session, get_chat_response
    
    # 1. Debug xem ƒë√£ ƒë·ªçc ƒë∆∞·ª£c n·ªôi dung CV ch∆∞a
    print(f"üìÑ [CV Review] ƒê√£ ƒë·ªçc ƒë∆∞·ª£c: {len(cv_text)} k√Ω t·ª± t·ª´ CV.")
    if len(cv_text) < 100:
        return "‚ö†Ô∏è L·ªói: Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c n·ªôi dung CV (File c√≥ th·ªÉ l√† ·∫£nh scan ho·∫∑c b·ªã l·ªói font). Vui l√≤ng th·ª≠ file PDF kh√°c.", "CV Error"

    # 2. T·∫°o Search Query th√¥ng minh h∆°n
    # Thay v√¨ t√¨m nguy√™n vƒÉn c·∫£ CV, ta tr√≠ch xu·∫•t 500 k√Ω t·ª± ƒë·∫ßu (th∆∞·ªùng ch·ª©a Tech Stack) 
    # v√† th√™m t·ª´ kh√≥a ƒë·ªÉ √©p Vector t√¨m v·ªÅ ph√≠a Job/Company thay v√¨ t√†i li·ªáu OJT.
    search_query = cv_text[:500] + " T√¨m vi·ªác l√†m ph√π h·ª£p cho ·ª©ng vi√™n d·ª±a tr√™n k·ªπ nƒÉng c√¥ng ngh·ªá v√† kinh nghi·ªám l√†m vi·ªác."
    
    # 3. T√¨m ki·∫øm Job trong DB
    # (L·∫•y k·∫øt qu·∫£ context t·ª´ h√†m search_vectors c√≥ s·∫µn)
    context = search_vectors(search_query)
    
    # 4. Prompt "Match Maker" (So kh·ªõp ·ª©ng vi√™n & Vi·ªác l√†m)
    prompt = f"""
    VAI TR√í: B·∫°n l√† chuy√™n gia HR. Nhi·ªám v·ª• l√† gh√©p ƒë√¥i ·ª©ng vi√™n v·ªõi c√¥ng vi·ªác ph√π h·ª£p nh·∫•t.

    D·ªÆ LI·ªÜU ƒê·∫¶U V√ÄO:
    ----------------
    1. H·ªí S∆† ·ª®NG VI√äN (CV):
    {cv_text[:3000]} ... (l∆∞·ª£c b·ªõt)
    
    2. DANH S√ÅCH VI·ªÜC L√ÄM TRONG H·ªÜ TH·ªêNG (Database):
    {context}
    
    3. C√ÇU H·ªéI C·ª¶A ·ª®NG VI√äN: "{user_message}"
    ----------------
    
    Y√äU C·∫¶U PH√ÇN T√çCH:
    1. B·ªé QUA c√°c t√†i li·ªáu h∆∞·ªõng d·∫´n OJT (File PDF quy ƒë·ªãnh). Ch·ªâ t·∫≠p trung v√†o [VI·ªÜC L√ÄM] ho·∫∑c [DOANH NGHI·ªÜP].
    2. Ph√¢n t√≠ch k·ªπ nƒÉng c·ª©ng (Hard Skills) trong CV (VD: Java, React, Python, SQL...).
    3. So s√°nh v·ªõi "Y√™u c·∫ßu" (Requirements) c·ªßa c√°c Job t√¨m th·∫•y.
    4. ƒê∆∞a ra Top 3 c√¥ng ty/v·ªã tr√≠ ph√π h·ª£p nh·∫•t.
    
    ƒê·ªäNH D·∫†NG TR·∫¢ L·ªúI (B·∫Øt bu·ªôc):
    üéØ **Top 1: [T√™n V·ªã Tr√≠] - [T√™n C√¥ng Ty]**
       - üí° ƒê·ªô ph√π h·ª£p: [Cao/Kh√°]
       - ‚úÖ L√Ω do match: [K·ªπ nƒÉng n√†o trong CV kh·ªõp v·ªõi Job?]
       - ‚ö†Ô∏è C·∫ßn b·ªï sung: [Job y√™u c·∫ßu g√¨ m√† CV ch∆∞a c√≥?]

    üéØ **Top 2: ...**
    
    (N·∫øu kh√¥ng t√¨m th·∫•y Job n√†o ph√π h·ª£p, h√£y ƒë∆∞a ra l·ªùi khuy√™n c·∫£i thi·ªán CV d·ª±a tr√™n th·ªã tr∆∞·ªùng).
    """
    
    print("ü§ñ [CV Review] ƒêang ph√¢n t√≠ch ƒë·ªô ph√π h·ª£p...")
    return get_chat_response(start_chat_session(), prompt), "CV Reviewer Intelligence"
