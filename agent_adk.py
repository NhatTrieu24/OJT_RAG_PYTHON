import os
import time
import psycopg2
import vertexai
from vertexai.language_models import TextEmbeddingModel
from tenacity import retry, stop_after_attempt, wait_exponential

# ==================== 1. C·∫§U H√åNH AUTHENTICATION ====================
render_secret = "/etc/secrets/GCP_SERVICE_ACCOUNT_JSON"
local_key = "rag-service-account.json" 

if os.path.exists(render_secret): 
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = render_secret
    print("üîë [Auth] S·ª≠ d·ª•ng Key t·ª´ Render Secrets.")
elif os.path.exists(local_key): 
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = os.path.abspath(local_key)
    print("üîë [Auth] S·ª≠ d·ª•ng Key t·ª´ file Local.")
else:
    print("‚ùå [Auth] Kh√¥ng t√¨m th·∫•y Service Account Key!")

PROJECT_ID = os.getenv("PROJECT_ID", "reflecting-surf-477600-p4")
LOCATION = os.getenv("LOCATION", "us-west1")
DB_DSN = os.getenv("DB_DSN", "postgresql://postgres:123@caboose.proxy.rlwy.net:54173/railway")

embedding_model = None
try:
    vertexai.init(project=PROJECT_ID, location=LOCATION)
    embedding_model = TextEmbeddingModel.from_pretrained("text-embedding-004")
    print("‚úÖ [Agent] Vertex AI & Embedding Model Ready.")
except Exception as e:
    print(f"‚ö†Ô∏è [Agent] Init Error: {e}")

# ==================== 2. EMBEDDING (BATCH & RETRY) ====================

@retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=2, min=5, max=60))
def get_embeddings_batch(texts):
    if not embedding_model or not texts: return []
    clean_texts = [str(t).replace("\n", " ").strip()[:3000] for t in texts if t]
    if not clean_texts: return []
    try:
        embeddings = embedding_model.get_embeddings(clean_texts)
        return [e.values for e in embeddings]
    except Exception as e:
        print(f"‚ö†Ô∏è API Warning: {e}. ƒêang th·ª≠ l·∫°i...")
        raise e

def get_query_embedding(text):
    res = get_embeddings_batch([text])
    return res[0] if res else None

# ==================== 3. ƒê·ªíNG B·ªò VECTOR (PH·∫≤NG H√ìA D·ªÆ LI·ªÜU) ====================

def get_existing_columns(cur, table_name):
    try:
        cur.execute(f'SELECT * FROM "{table_name}" LIMIT 0')
        return [desc[0] for desc in cur.description]
    except: return []

import psycopg2
import time

def sync_missing_embeddings():
    print("üîÑ [System] B·∫Øt ƒë·∫ßu quy tr√¨nh Ph·∫≥ng h√≥a & ƒê·ªìng b·ªô Vector to√†n di·ªán...")
    conn = None
    try:
        conn = psycopg2.connect(dsn=DB_DSN)
        cur = conn.cursor()
        
        # --- 1. PH·∫≤NG H√ìA JOB_POSITION (G·ªôp C√¥ng ty + K·ª≥ h·ªçc + Chuy√™n ng√†nh) ---
        print("   ‚àü X·ª≠ l√Ω: job_position (Flattened: Company, Semester, Major)")
        sql_job = """
            SELECT jp.job_position_id, 
                   'V·ªã tr√≠ tuy·ªÉn d·ª•ng: ' || COALESCE(jp.job_title, '') || 
                   '. T·∫°i c√¥ng ty: ' || COALESCE(c.name, 'N/A') || 
                   '. Y√™u c·∫ßu: ' || COALESCE(jp.requirements, 'Kh√¥ng c√≥') || 
                   '. Quy·ªÅn l·ª£i: ' || COALESCE(jp.benefit, 'Trao ƒë·ªïi th√™m') ||
                   '. ƒê·ªãa ƒëi·ªÉm: ' || COALESCE(jp.location, 'To√†n qu·ªëc') || 
                   '. D√†nh cho k·ª≥: ' || COALESCE(s.name, 'N/A') ||
                   '. Thu·ªôc ng√†nh: ' || COALESCE(m.major_title, 'N/A') as full_text
            FROM job_position jp
            LEFT JOIN semester_company sc ON jp.semester_company_id = sc.semester_company_id
            LEFT JOIN company c ON sc.company_id = c.company_id
            LEFT JOIN semester s ON jp.semester_id = s.semester_id
            LEFT JOIN major m ON jp.major_id = m.major_id
            WHERE jp.embedding IS NULL;
        """
        process_batch_sync(cur, conn, sql_job, "job_position", "job_position_id")

        # --- 2. PH·∫≤NG H√ìA OJT_DOCUMENT (G·ªôp K·ª≥ h·ªçc) ---
        print("   ‚àü X·ª≠ l√Ω: ojtdocument (Flattened: Semester)")
        sql_ojtdoc = """
            SELECT od.ojtdocument_id, 
                   'T√†i li·ªáu quy ƒë·ªãnh OJT: ' || COALESCE(od.title, '') || 
                   '. √Åp d·ª•ng cho k·ª≥ h·ªçc: ' || COALESCE(s.name, 'Chung') as full_text
            FROM ojtdocument od
            LEFT JOIN semester s ON od.semester_id = s.semester_id
            WHERE od.embedding IS NULL;
        """
        process_batch_sync(cur, conn, sql_ojtdoc, "ojtdocument", "ojtdocument_id")

        # --- 3. PH·∫≤NG H√ìA USER (G·ªôp Chuy√™n ng√†nh + C√¥ng ty th·ª±c t·∫≠p) ---
        print("   ‚àü X·ª≠ l√Ω: User (Flattened: Major, Company)")
        sql_user = """
            SELECT u.user_id, 
                   'Sinh vi√™n: ' || COALESCE(u.fullname, '') || 
                   '. MSSV: ' || COALESCE(u.student_code, 'N/A') ||
                   '. Ng√†nh h·ªçc: ' || COALESCE(m.major_title, 'N/A') || 
                   '. C√¥ng ty ƒëang th·ª±c t·∫≠p: ' || COALESCE(c.name, 'Ch∆∞a ƒëi th·ª±c t·∫≠p') as full_text
            FROM "User" u
            LEFT JOIN major m ON u.major_id = m.major_id
            LEFT JOIN company c ON u.company_id = c.company_id
            WHERE u.embedding IS NULL;
        """
        process_batch_sync(cur, conn, sql_user, "User", "user_id")

        # --- 4. PH·∫≤NG H√ìA FINALREPORT (G·ªôp SV + Job + K·ª≥ h·ªçc) ---
        print("   ‚àü X·ª≠ l√Ω: finalreport (Flattened: Student, Job, Semester)")
        sql_report = """
            SELECT fr.finalreport_id,
                   'B√°o c√°o cu·ªëi k·ª≥ c·ªßa SV: ' || COALESCE(u.fullname, '') ||
                   '. V·ªã tr√≠ th·ª±c t·∫≠p: ' || COALESCE(jp.job_title, '') ||
                   '. K·ª≥ h·ªçc: ' || COALESCE(s.name, '') ||
                   '. N·ªôi dung b√°o c√°o: ' || COALESCE(fr.student_report_text, '') ||
                   '. Nh·∫≠n x√©t c√¥ng ty: ' || COALESCE(fr.company_feedback, '') as full_text
            FROM finalreport fr
            LEFT JOIN "User" u ON fr.user_id = u.user_id
            LEFT JOIN job_position jp ON fr.job_position_id = jp.job_position_id
            LEFT JOIN semester s ON fr.semester_id = s.semester_id
            WHERE fr.embedding IS NULL;
        """
        process_batch_sync(cur, conn, sql_report, "finalreport", "finalreport_id")

        # --- 5. C√ÅC B·∫¢NG DANH M·ª§C (Company, Major, Semester) ---
        targets = [
            ("company", "name", "company_id"),
            ("semester", "name", "semester_id"),
            ("major", "major_title", "major_id"),
            ("companydocument", "title", "companydocument_id")
        ]
        for table, col, id_col in targets:
            sql_simple = f'SELECT "{id_col}", "{col}" FROM "{table}" WHERE embedding IS NULL AND "{col}" IS NOT NULL'
            process_batch_sync(cur, conn, sql_simple, table, id_col)

        print("üéâ [System] Ho√†n t·∫•t ph·∫≥ng h√≥a to√†n b·ªô Database.")
    except Exception as e:
        print(f"‚ùå L·ªói ƒë·ªìng b·ªô: {e}")
        if conn: conn.rollback()
    finally:
        if conn: conn.close()

def process_batch_sync(cur, conn, sql, table_name, id_col):
    cur.execute(sql)
    rows = cur.fetchall()
    if not rows: return
    
    print(f"      -> C·∫≠p nh·∫≠t {len(rows)} d√≤ng cho [{table_name}]")
    ids = [r[0] for r in rows]
    texts = [r[1] for r in rows]
    
    # Chia nh·ªè batch 50 ƒë·ªÉ tr√°nh l·ªói Rate Limit c·ªßa Vertex AI
    batch_size = 50
    for i in range(0, len(rows), batch_size):
        sub_ids = ids[i : i + batch_size]
        sub_texts = texts[i : i + batch_size]
        try:
            vectors = get_embeddings_batch(sub_texts)
            for rid, vec in zip(sub_ids, vectors):
                cur.execute(f'UPDATE "{table_name}" SET embedding = %s WHERE "{id_col}" = %s', (vec, rid))
            conn.commit()
        except Exception as e:
            print(f"      ‚ö†Ô∏è L·ªói batch t·∫°i {table_name}: {e}")
            conn.rollback()
# ==================== 4. SEARCH & RAG ====================

def search_vectors(question, target_table="auto", limit=5):
    query_vector = get_query_embedding(question)
    if not query_vector: return ""

    conn = None
    try:
        conn = psycopg2.connect(dsn=DB_DSN)
        cur = conn.cursor()
        
        q_lower = question.lower()
        
        # 1. Nh·∫≠n di·ªán b·∫£ng m·ª•c ti√™u
        mapping = {
            "semester": ["k·ª≥", "h·ªçc k·ª≥", "spring", "summer", "fall", "2025"],
            "company": ["ƒë·ªãa ch·ªâ", "website", "li√™n h·ªá", "vƒÉn ph√≤ng"],
            "ojtdocument": ["ojt", "quy ƒë·ªãnh", "h∆∞·ªõng d·∫´n", "t√†i li·ªáu"],
            "job_position": ["vi·ªác l√†m", "tuy·ªÉn d·ª•ng", "job", "l∆∞∆°ng", "v·ªã tr√≠", "momo", "fpt"]
        }

        tables_to_search = []
        for tbl, keywords in mapping.items():
            if any(k in q_lower for k in keywords):
                tables_to_search.append(tbl)
        
        if not tables_to_search:
            tables_to_search = ["job_position", "company", "ojtdocument"]

        final_results = []
        for table in set(tables_to_search):
            # --- LOGIC ƒê·∫∂C BI·ªÜT CHO JOB_POSITION: JOIN B·∫ÆC C·∫¶U ---
            if table == "job_position":
                sql = """
                    SELECT 
                        jp.job_title, jp.location, jp.salary_range, jp.requirements,
                        c.name as company_name,
                        1 - (jp.embedding <=> %s::vector) as sim
                    FROM job_position jp
                    LEFT JOIN semester_company sc ON jp.semester_company_id = sc.semester_company_id
                    LEFT JOIN company c ON sc.company_id = c.company_id
                    WHERE jp.embedding IS NULL OR jp.embedding IS NOT NULL 
                    ORDER BY jp.embedding <=> %s::vector LIMIT %s
                """
                cur.execute(sql, (query_vector, query_vector, limit))
                for r in cur.fetchall():
                    if r[-1] > 0.20: # Ng∆∞·ª°ng th·∫•p ƒë·ªÉ b·∫Øt ƒë∆∞·ª£c d·ªØ li·ªáu li√™n quan MoMo
                        final_results.append(
                            f"[JOB] V·ªã tr√≠: {r[0]} | C√¥ng ty: {r[4]} | ƒê·ªãa ƒëi·ªÉm: {r[1]} | "
                            f"L∆∞∆°ng: {r[2]} | Y√™u c·∫ßu: {r[3]}"
                        )
            
            # --- LOGIC CHO C√ÅC B·∫¢NG KH√ÅC (GI·ªÆ NGUY√äN) ---
            else:
                cols = get_existing_columns(cur, table)
                if "embedding" not in cols: continue
                d_map = {
                    "semester": ["name", "start_date"],
                    "company": ["name", "address", "website"],
                    "ojtdocument": ["title", "file_url"]
                }
                s_cols = [c for c in d_map.get(table, []) if c in cols] or cols[:2]
                cols_sql = ", ".join([f'"{c}"' for c in s_cols])

                sql = f'SELECT {cols_sql}, 1 - (embedding <=> %s::vector) FROM "{table}" ORDER BY embedding <=> %s::vector LIMIT 3'
                cur.execute(sql, (query_vector, query_vector))
                for r in cur.fetchall():
                    if r[-1] > 0.30:
                        content = " | ".join([f"{s_cols[j]}: {r[j]}" for j in range(len(s_cols)) if r[j]])
                        final_results.append(f"[{table.upper()}] {content}")

        context_str = "\n".join(final_results)
        print(f"üîç [Search] Context b·ªëc ƒë∆∞·ª£c: \n{context_str[:500]}...")
        return context_str

    except Exception as e:
        print(f"‚ùå Search Error: {e}")
        return ""
    finally:
        if conn: conn.close()

# ==================== 5. H√ÄM REVIEW CV & AGENT ====================

def run_agent(question: str, file_content: str = None):
    from rag_core import start_chat_session, get_chat_response
    db_context = search_vectors(question)
    prompt = f"D·ªÆ LI·ªÜU H·ªÜ TH·ªêNG:\n{db_context}\n\nC√ÇU H·ªéI: {question}"
    return get_chat_response(start_chat_session(), prompt), "Mode: Clean RAG Vector"

def run_cv_review(cv_text: str, user_message: str):
    from rag_core import start_chat_session
    # Khi t√¨m job cho CV, Vector Search s·∫Ω t·ª± kh·ªõp c√°c Job ƒë√£ ƒë∆∞·ª£c ph·∫≥ng h√≥a v·ªõi t√™n c√¥ng ty
    matched_jobs = search_vectors(cv_text, target_table="job_position", limit=3)
    prompt = f"CV: {cv_text[:3000]}\nJob g·ª£i √Ω: {matched_jobs}\nY√™u c·∫ßu: {user_message}"
    chat_session = start_chat_session()
    return chat_session.send_message(prompt).text, "Mode: CV Reviewer"

def check_vector_coverage():
    print("\nüìä [REPORT] KI·ªÇM TRA ƒê·ªò PH·ª¶ VECTOR")
    conn = None
    try:
        conn = psycopg2.connect(dsn=DB_DSN)
        cur = conn.cursor()
        targets = [("semester", "semester_id"), ("company", "company_id"), ("job_position", "job_position_id"), ("ojtdocument", "ojtdocument_id")]
        for table, id_col in targets:
            cur.execute(f'SELECT COUNT(*), COUNT(embedding) FROM "{table}"')
            total, has_vec = cur.fetchone()
            print(f"[{table}]: {has_vec}/{total} d√≤ng.")
    except Exception as e: print(f"L·ªói: {e}")
    finally:
        if conn: conn.close()