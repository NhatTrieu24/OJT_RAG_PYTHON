import os
import time
import psycopg2
import vertexai
from vertexai.language_models import TextEmbeddingModel
from tenacity import retry, stop_after_attempt, wait_exponential

# ==================== 1. C·∫§U H√åNH AUTHENTICATION ====================
render_secret = "/etc/secrets/GCP_SERVICE_ACCOUNT_JSON"
local_key = "rag-service-account.json" 

if os.path.exists(render_secret): 
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = render_secret
    print("üîë [Auth] S·ª≠ d·ª•ng Key t·ª´ Render Secrets.")
elif os.path.exists(local_key): 
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = os.path.abspath(local_key)
    print("üîë [Auth] S·ª≠ d·ª•ng Key t·ª´ file Local.")
else:
    print("‚ùå [Auth] Kh√¥ng t√¨m th·∫•y Service Account Key!")

PROJECT_ID = os.getenv("PROJECT_ID", "reflecting-surf-477600-p4")
LOCATION = os.getenv("LOCATION", "us-west1")
DB_DSN = os.getenv("DB_DSN", "postgresql://postgres:123@caboose.proxy.rlwy.net:54173/railway")

embedding_model = None
try:
    vertexai.init(project=PROJECT_ID, location=LOCATION)
    embedding_model = TextEmbeddingModel.from_pretrained("text-embedding-004")
    print("‚úÖ [Agent] Vertex AI & Embedding Model Ready.")
except Exception as e:
    print(f"‚ö†Ô∏è [Agent] Init Error: {e}")

# ==================== 2. EMBEDDING (BATCH & RETRY) ====================

@retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=2, min=5, max=60))
def get_embeddings_batch(texts):
    if not embedding_model or not texts: return []
    clean_texts = [str(t).replace("\n", " ").strip()[:3000] for t in texts if t]
    if not clean_texts: return []
    try:
        embeddings = embedding_model.get_embeddings(clean_texts)
        return [e.values for e in embeddings]
    except Exception as e:
        print(f"‚ö†Ô∏è API Warning: {e}. ƒêang th·ª≠ l·∫°i...")
        raise e

def get_query_embedding(text):
    res = get_embeddings_batch([text])
    return res[0] if res else None

# ==================== 3. ƒê·ªíNG B·ªò VECTOR (SMART SYNC & FORCE RESET) ====================

def sync_all_data(force_reset=False):
    """
    H√†m ƒë·ªìng b·ªô th√¥ng minh t√≠ch h·ª£p Reset.
    - force_reset=True: X√≥a s·∫°ch Vector c≈© ƒë·ªÉ t·∫°o l·∫°i theo c·∫•u tr√∫c ph·∫≥ng h√≥a m·ªõi.
    """
    print(f"üîÑ [System] B·∫Øt ƒë·∫ßu ƒë·ªìng b·ªô {'(L√ÄM M·ªöI TO√ÄN B·ªò)' if force_reset else ''}...")
    conn = None
    try:
        conn = psycopg2.connect(dsn=DB_DSN)
        cur = conn.cursor()

        if force_reset:
            print("‚ö†Ô∏è [Reset] ƒêang x√≥a s·∫°ch d·ªØ li·ªáu Vector v√† Index c≈© tr√™n t·∫•t c·∫£ b·∫£ng c·ªët l√µi...")
            tables_to_reset = [
                "job_position", "company", "semester", "User", "major", 
                "ojtdocument", "job_description", "companydocument", "job_title_overview"
            ]
            for table in tables_to_reset:
                try:
                    cur.execute(f'UPDATE "{table}" SET embedding = NULL, last_content_indexed = NULL;')
                except: pass
            conn.commit()

        scenarios = [
            {
                "table": "job_position",
                "id_col": "job_position_id",
                "sql": """
                    SELECT jp.job_position_id as id, 
                           'TH√îNG TIN TUY·ªÇN D·ª§NG: V·ªã tr√≠ ' || COALESCE(jp.job_title, '') || 
                           '. T·∫°i c√¥ng ty: ' || COALESCE(c.name, 'N/A') || 
                           '. M·ª©c l∆∞∆°ng: ' || COALESCE(jp.salary_range, 'Th·ªèa thu·∫≠n') || 
                           '. Y√™u c·∫ßu: ' || COALESCE(jp.requirements, 'Kh√¥ng c√≥') || 
                           '. ƒê·ªãa ƒëi·ªÉm: ' || COALESCE(jp.location, 'N/A') as text
                    FROM job_position jp
                    LEFT JOIN semester_company sc ON jp.semester_company_id = sc.semester_company_id
                    LEFT JOIN company c ON sc.company_id = c.company_id
                """
            },
            {
                "table": "ojtdocument",
                "id_col": "ojtdocument_id",
                "sql": "SELECT ojtdocument_id as id, 'T√ÄI LI·ªÜU OJT: ' || COALESCE(title, '') || '. Link t·∫£i: ' || COALESCE(file_url, '') as text FROM ojtdocument"
            },
            {
                "table": "semester",
                "id_col": "semester_id",
                "sql": "SELECT semester_id as id, 'L·ªäCH K·ª≤ H·ªåC: ' || COALESCE(name, '') || '. B·∫Øt ƒë·∫ßu: ' || COALESCE(start_date::text, '') || '. K·∫øt th√∫c: ' || COALESCE(end_date::text, '') as text FROM semester"
            },
            {
                "table": "User",
                "id_col": "user_id",
                "sql": "SELECT user_id as id, 'H·ªí S∆†: ' || COALESCE(fullname, '') || '. MSSV: ' || COALESCE(student_code, 'N/A') || '. Vai tr√≤: ' || COALESCE(role, '') as text FROM \"User\""
            },
            {
                "table": "company",
                "id_col": "company_id",
                "sql": "SELECT company_id as id, 'C√îNG TY: ' || COALESCE(name, '') || '. ƒê·ªãa ch·ªâ: ' || COALESCE(address, '') || '. Web: ' || COALESCE(website, '') as text FROM company"
            },
            {
                "table": "major",
                "id_col": "major_id",
                "sql": "SELECT major_id as id, 'NG√ÄNH H·ªåC: ' || COALESCE(major_title, '') || '. M√¥ t·∫£: ' || COALESCE(description, '') as text FROM major"
            }
        ]

        for sc in scenarios:
            table = sc['table']
            id_col = sc['id_col']
            
            sync_query = f"""
                WITH latest_text AS ({sc['sql']})
                SELECT lt.id, lt.text 
                FROM latest_text lt
                LEFT JOIN "{table}" t ON lt.id = t."{id_col}"
                WHERE t.embedding IS NULL 
                   OR t.last_content_indexed IS NULL 
                   OR lt.text <> t.last_content_indexed;
            """
            cur.execute(sync_query)
            rows = cur.fetchall()
            
            if rows:
                print(f"   üì¶ B·∫£ng [{table}]: C·∫≠p nh·∫≠t {len(rows)} d√≤ng.")
                process_batch_sync(cur, conn, rows, table, id_col)
            else:
                print(f"   ‚úÖ B·∫£ng [{table}]: ƒê√£ ƒë·ªìng b·ªô.")

        print("üéâ [System] To√†n b·ªô Database ƒë√£ ·ªü tr·∫°ng th√°i m·ªõi nh·∫•t.")
    except Exception as e:
        print(f"‚ùå L·ªói: {e}"); 
        if conn: conn.rollback()
    finally:
        if conn: conn.close()

def process_batch_sync(cur, conn, rows, table_name, id_col):
    batch_size = 50
    for i in range(0, len(rows), batch_size):
        batch = rows[i : i + batch_size]
        ids = [r[0] for r in batch]
        texts = [r[1] for r in batch]
        vectors = get_embeddings_batch(texts)
        if vectors:
            for idx, vec in enumerate(vectors):
                cur.execute(f'UPDATE "{table_name}" SET embedding = %s, last_content_indexed = %s WHERE "{id_col}" = %s', 
                            (vec, texts[idx], ids[idx]))
            conn.commit()

# ==================== 4. SEARCH & RAG ====================

def search_vectors(question, limit=10):
    query_vector = get_query_embedding(question)
    if not query_vector: return ""
    conn = None
    try:
        conn = psycopg2.connect(dsn=DB_DSN)
        cur = conn.cursor()
        q_lower = question.lower()
        threshold = 0.18 if any(k in q_lower for k in ["l∆∞∆°ng", "ng√†y", "mssv", "link", "url"]) else 0.25

        tables = ["job_position", "company", "ojtdocument", "semester", "major", "User"]
        final_results = []

        for table in tables:
            sql = f'SELECT last_content_indexed, 1 - (embedding <=> %s::vector) FROM "{table}" WHERE embedding IS NOT NULL ORDER BY embedding <=> %s::vector LIMIT 5'
            cur.execute(sql, (query_vector, query_vector))
            for r in cur.fetchall():
                if r[1] > threshold:
                    final_results.append(f"[{table.upper()}] {r[0]}")
        return "\n".join(final_results)
    finally:
        if conn: conn.close()

def run_agent(question: str, file_content: str = None):
    from rag_core import start_chat_session, get_chat_response
    # Nh·ªù AI s·ª≠a l·ªói ch√≠nh t·∫£ v√† bung vi·∫øt t·∫Øt (Query Expansion)
    
    refine_prompt = f"""
    B·∫°n l√† chuy√™n gia x·ª≠ l√Ω ng√¥n ng·ªØ. Nhi·ªám v·ª• c·ªßa b·∫°n l√† chu·∫©n h√≥a c√¢u h·ªèi c·ªßa sinh vi√™n.
    - Bung vi·∫øt t·∫Øt: tt -> th·ª±c t·∫≠p, sv -> sinh vi√™n, mssv -> m√£ s·ªë sinh vi√™n, cty -> c√¥ng ty, nv -> nh√¢n vi√™n.
    - Gi·ªØ nguy√™n t√™n ri√™ng/c√¥ng ty: MoMo, FPT, Viettel, VNG, Shopee...
    - S·ª≠a l·ªói ch√≠nh t·∫£ v√† th√™m d·∫•u n·∫øu thi·∫øu.
    - N·∫øu c√≥ t·ª´ 'm√¥ m√¥', h√£y hi·ªÉu ƒë√≥ l√† c√¥ng ty 'MoMo'.
    
    C√¢u h·ªèi g·ªëc: "{question}"
    C√¢u h·ªèi ƒë√£ chu·∫©n h√≥a (ch·ªâ tr·∫£ v·ªÅ n·ªôi dung c√¢u):"""
    
    refine_session = start_chat_session()
    clean_question = refine_session.send_message(refine_prompt).text.strip()
    #-----------------------------------------------------------
    print(f"üîç [Refine] G·ªëc: {question} -> ƒê√£ s·ª≠a: {clean_question}")
    db_context = search_vectors(clean_question)
    prompt = f"D·ªÆ LI·ªÜU H·ªÜ TH·ªêNG:\n{db_context}\n\nC√ÇU H·ªéI: {clean_question}\n\nY√äU C·∫¶U: CH·ªà d√πng d·ªØ li·ªáu tr√™n. Tr·∫£ l·ªùi ch√≠nh x√°c L∆∞∆°ng/Ng√†y/MSSV/URL."
    print(f"--- DEBUG CONTEXT ---\n{db_context}")
    return get_chat_response(start_chat_session(), prompt), "Mode: Smart Deep RAG"
   
def run_cv_review(cv_text: str, user_message: str):
    from rag_core import start_chat_session
    
    # S·ª≠ d·ª•ng n·ªôi dung CV ƒë·ªÉ t√¨m ki·∫øm c√°c c√¥ng vi·ªác ph√π h·ª£p nh·∫•t trong database
    # V√¨ cv_text th∆∞·ªùng d√†i, search_vectors s·∫Ω b·ªëc ra nh·ªØng job c√≥ y√™u c·∫ßu k·ªπ nƒÉng t∆∞∆°ng ƒë·ªìng
    matched_jobs = search_vectors(cv_text, limit=5) 
    
    prompt = f"""
    H·ªí S∆† SINH VI√äN (CV): 
    {cv_text[:3500]} 
    
    C√ÅC V·ªä TR√ç TUY·ªÇN D·ª§NG V√Ä QUY ƒê·ªäNH OJT T√åM TH·∫§Y: 
    {matched_jobs}
    
    Y√äU C·∫¶U C·ª¶A NG∆Ø·ªúI D√ôNG: {user_message}
    
    H∆Ø·ªöNG D·∫™N TR·∫¢ L·ªúI:
    1. Ph√¢n t√≠ch s·ª± ph√π h·ª£p gi·ªØa k·ªπ nƒÉng trong CV v√† y√™u c·∫ßu c·ªßa c√°c Job.
    2. ƒê√°nh gi√° sinh vi√™n c√≥ ƒë·ªß ƒëi·ªÅu ki·ªán ƒëi OJT theo quy ƒë·ªãnh c·ªßa tr∆∞·ªùng kh√¥ng.
    3. Tr·∫£ l·ªùi b·∫±ng Ti·∫øng Vi·ªát, tr√¨nh b√†y r√µ r√†ng, chuy√™n nghi·ªáp. 
    4. N·∫øu ƒë·ªß ƒëi·ªÅu ki·ªán, h√£y g·ª£i √Ω v·ªã tr√≠ kh·ªõp nh·∫•t. N·∫øu ch∆∞a, h√£y ch·ªâ ra k·ªπ nƒÉng c·∫ßn b·ªï sung.
    """
    
    print(f"--- [Mode: CV Review] ƒê√£ b·ªëc {len(matched_jobs)} ƒëo·∫°n ng·ªØ c·∫£nh cho CV ---")
    chat_session = start_chat_session()
    return chat_session.send_message(prompt).text, "Mode: CV Reviewer Intelligence"
def check_vector_coverage():
    print("\nüìä [REPORT] KI·ªÇM TRA ƒê·ªò PH·ª¶ VECTOR")
    conn = None
    try:
        conn = psycopg2.connect(dsn=DB_DSN)
        cur = conn.cursor()
        targets = [("semester", "semester_id"), ("company", "company_id"), ("job_position", "job_position_id"), ("ojtdocument", "ojtdocument_id")]
        for table, id_col in targets:
            cur.execute(f'SELECT COUNT(*), COUNT(embedding) FROM "{table}"')
            total, has_vec = cur.fetchone()
            print(f"[{table}]: {has_vec}/{total} d√≤ng.")
    except Exception as e: print(f"L·ªói: {e}")
    finally:
        if conn: conn.close()